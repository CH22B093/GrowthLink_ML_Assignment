# -*- coding: utf-8 -*-
"""Credit Card Fraud Detection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1yBA7VHqvd8DxT8GkwH6a9uC0zT5rKx1T

# Importing Necessary Libraries
"""

!pip install xgboost imbalanced-learn
import numpy as np
import pandas as pd
import xgboost as xgb
from xgboost import XGBClassifier
from sklearn.preprocessing import LabelEncoder,StandardScaler
from sklearn.metrics import classification_report,roc_auc_score,confusion_matrix
from imblearn.over_sampling import SMOTE

"""# Loading the dataset"""

df_train = pd.read_csv('fraudTrain.csv')
df_test = pd.read_csv('fraudTest.csv')
df_train.drop(columns = ["Unnamed: 0", "cc_num", "first", "last", "street", "trans_num"],inplace = True,errors = 'ignore')
df_test.drop(columns = ["Unnamed: 0", "cc_num", "first", "last", "street", "trans_num"],inplace = True,errors = 'ignore')

"""# Convert date column to useful features"""

# for the training set
df_train['trans_date_trans_time'] = pd.to_datetime(df_train['trans_date_trans_time'])
df_train['hour'] = df_train['trans_date_trans_time'].dt.hour
df_train['day_of_week'] = df_train['trans_date_trans_time'].dt.dayofweek
df_train['is_weekend'] = (df_train['day_of_week'] >=5).astype(int)
df_train.drop(columns=['trans_date_trans_time'], inplace=True)

# for the test set
df_test['trans_date_trans_time'] = pd.to_datetime(df_test['trans_date_trans_time'])
df_test['hour'] = df_test['trans_date_trans_time'].dt.hour
df_test['day_of_week'] = df_test['trans_date_trans_time'].dt.dayofweek
df_test['is_weekend'] = (df_test['day_of_week'] >=5).astype(int)
df_test.drop(columns=['trans_date_trans_time'], inplace=True)

"""# Encoding the categorical variables"""

cat_var = df_train.select_dtypes(include = ['object']).columns
df_train[cat_var] = df_train[cat_var].apply(lambda col: LabelEncoder().fit_transform(col))
df_test[cat_var] = df_test[cat_var].apply(lambda col: LabelEncoder().fit_transform(col))
print(df_train.head(3))

"""# Specifying the training and test data as input and output data"""

X_train = df_train.drop('is_fraud', axis=1)
y_train = df_train['is_fraud']
X_test = df_test.drop('is_fraud', axis=1)
y_test = df_test['is_fraud']
print(X_train)
print(y_train)

"""# Handling Class Imbalance using SMOTE"""

smote = SMOTE(random_state = 42)
X_resampled_train,y_resampled_train = smote.fit_resample(X_train,y_train)
X_resampled_test,y_resampled_test = smote.fit_resample(X_test,y_test)

"""# Feature Scaling"""

scaler = StandardScaler()
X_resampled_train = scaler.fit_transform(X_resampled_train)
X_resampled_test = scaler.transform(X_resampled_test)

"""# Training XGBoost Classifier"""

xgb_clf = XGBClassifier(objective="binary:logistic",eval_metric="logloss",use_label_encoder=False,random_state=42)
xgb_clf.fit(X_resampled_train,y_resampled_train)

"""# Predticing using X_resampled_test"""

y_pred = xgb_clf.predict(X_resampled_test)

"""# Evaualtion Metrics"""

# Compute confusion matrix
cm = confusion_matrix(y_resampled_test,y_pred)
labels = ["Not Fraud", "Fraud"]
import matplotlib.pyplot as plt
import seaborn as sns
# Plot confusion matrix as heatmap
plt.figure(figsize=(6, 5))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=labels, yticklabels=labels)
plt.xlabel("Predicted Label")
plt.ylabel("True Label")
plt.title("Confusion Matrix")
plt.show()

print("\nClassification Report:\n", classification_report(y_resampled_test,y_pred))
print("\nROC-AUC Score:", roc_auc_score(y_resampled_test,y_pred))

"""# Precision-Recall Curve"""

y_pred_probs = xgb_clf.predict_proba(X_resampled_test)[:,1]
from sklearn.metrics import precision_recall_curve
precision,recall,_ = precision_recall_curve(y_resampled_test,y_pred_probs)
plt.figure(figsize=(6,5))
plt.plot(recall,precision,marker='.',label='Precision-Recall Curve')
plt.xlabel('Recall')
plt.ylabel('Precision')
plt.title('Precision-Recall Curve')
plt.legend()
plt.show()

"""# Roc Curve"""

from sklearn.metrics import roc_curve, auc
fpr,tpr,_ = roc_curve(y_resampled_test,y_pred_probs)
roc_auc = auc(fpr,tpr)
plt.figure(figsize=(6,5))
plt.plot(fpr,tpr,color='blue',label=f'ROC curve (AUC = {roc_auc:.2f})')
plt.plot([0, 1],[0, 1],color='gray', linestyle='--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve')
plt.legend()
plt.show()

"""# Feature Importance"""

plt.figure(figsize=(8, 6))
xgb.plot_importance(xgb_clf)
plt.title("Feature Importance (XGBoost)")
plt.show()

# Get the feature names from training data
feature_names = X_train.columns.tolist()

# Print feature names to map them to f1, f2, etc.
for i, feature in enumerate(feature_names):
    print(f"f{i}:{feature}")